{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVfzVfv3K2KD"
   },
   "source": [
    "### Naive Bayes Classification and logistic regression for Face-Mask Detection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z30YX67YLI08"
   },
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in c:\\users\\user\\anaconda3\\lib\\site-packages (4.8.1.78)\n",
      "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from opencv-python) (1.26.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\user\\anaconda3\\lib\\site-packages (1.26.2)Note: you may need to restart the kernel to use updated packages.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "njsvHYwSTj5-"
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np \n",
    "import pickle\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24V4sfG7LARf"
   },
   "source": [
    "#### Load and Preprocess Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rZES7sgcWBCm"
   },
   "outputs": [],
   "source": [
    "# Define the paths to the image folders\n",
    "with_mask_folder = './data/with_mask'\n",
    "without_mask_folder = './data/without_mask'\n",
    "\n",
    "# Define the reshaped size\n",
    "reshaped_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5SN-iQc-WAFO",
    "outputId": "bc71cdf5-adc9-4a69-9aa9-63ed2737e83c"
   },
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_and_preprocess(folder_path, label):\n",
    "    images = []\n",
    "    labels = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(\".jpg\"):  \n",
    "            img_path = os.path.join(folder_path, filename)\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)  # Read image in grayscale\n",
    "            img_resized = cv2.resize(img, (reshaped_size, reshaped_size))\n",
    "            images.append(img_resized.flatten())\n",
    "            labels.append(label)\n",
    "    \n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 318
    },
    "id": "1lB3uH71Xq9N",
    "outputId": "a6d317dc-6989-4d6c-e53e-08c86f32adab"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess images with masks\n",
    "X_with_mask, y_with_mask = load_and_preprocess(with_mask_folder, label=1)\n",
    "\n",
    "# Load and preprocess images without masks\n",
    "X_without_mask, y_without_mask = load_and_preprocess(without_mask_folder, label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1dO3PNSnE-nl",
    "outputId": "1c3cf8f6-b340-458a-d38d-43e5725f3bf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Reshaping size: (7553, 4096)\n",
      "After Reshaping Size:  (7553, 64, 64)\n",
      "Before Reshaping to 1D: (7553, 64, 64)\n",
      "After Reshaping to 1D:  (7553, 4096)\n",
      "Domain: [ 0.0 , 1.0 ]\n"
     ]
    }
   ],
   "source": [
    "# Combine the datasets\n",
    "X = np.concatenate((X_with_mask, X_without_mask), axis=0)\n",
    "y = np.concatenate((y_with_mask, y_without_mask), axis=0)\n",
    "\n",
    "# Shuffle the dataset \n",
    "shuffle_indices = np.random.permutation(len(X))\n",
    "X = X[shuffle_indices]\n",
    "y = y[shuffle_indices]\n",
    "\n",
    "# Print shapes before reshaping and normalizing\n",
    "print('Before Reshaping size:', X.shape)\n",
    "\n",
    "# Reshape and normalize \n",
    "resized_X = []\n",
    "for img in X:\n",
    "    resized_X.append(cv2.resize(img.reshape(reshaped_size, reshaped_size), (reshaped_size, reshaped_size)))\n",
    "\n",
    "X = np.asarray(resized_X)\n",
    "del resized_X\n",
    "\n",
    "print('After Reshaping Size: ', X.shape)\n",
    "print('Before Reshaping to 1D:', X.shape)\n",
    "X = X.reshape(-1, reshaped_size * reshaped_size)\n",
    "print('After Reshaping to 1D: ', X.shape)\n",
    "\n",
    "# Normalize the data\n",
    "X = X / 255.0\n",
    "print('Domain: [', X.min(), ',', X.max(), ']')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "P3MDlNG3ejzC"
   },
   "outputs": [],
   "source": [
    "# Setting the proportion for training data\n",
    "train_proportion = 0.8\n",
    "num_samples = len(X)\n",
    "\n",
    "# Calculate the number of samples for training\n",
    "num_train = int(train_proportion * num_samples)\n",
    "\n",
    "# Split the data\n",
    "X_train, y_train = X[:num_train], y[:num_train]\n",
    "X_test, y_test = X[num_train:], y[num_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    total_samples = len(y_true)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes Accuracy: 69.89%\n"
     ]
    }
   ],
   "source": [
    "class GaussianNaiveBayes:\n",
    "    def _init_(self):\n",
    "        self.class_probs = None\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "        num_classes = len(unique_classes)\n",
    "\n",
    "        self.class_probs = np.zeros(num_classes)\n",
    "        self.mean = np.zeros((num_classes, num_features))\n",
    "        self.std = np.zeros((num_classes, num_features))\n",
    "\n",
    "        for i, c in enumerate(unique_classes):\n",
    "            class_mask = (y == c)\n",
    "            self.class_probs[i] = np.sum(class_mask) / num_samples\n",
    "\n",
    "            for j in range(num_features):\n",
    "                feature_values = X[class_mask, j]\n",
    "                self.mean[i, j] = np.mean(feature_values)\n",
    "                self.std[i, j] = np.std(feature_values)\n",
    "\n",
    "    def predict(self, X):\n",
    "        num_samples, num_features = X.shape\n",
    "        num_classes = len(self.class_probs)\n",
    "        predictions = np.zeros(num_samples)\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            posteriors = np.zeros(num_classes)\n",
    "            for j in range(num_classes):\n",
    "                class_prob = np.log(self.class_probs[j])\n",
    "                feature_probs = np.sum(\n",
    "                    -0.5 * ((X[i] - self.mean[j]) / (self.std[j] + 1e-10))**2 -\n",
    "                    np.log(self.std[j] + 1e-10)\n",
    "                )\n",
    "                posteriors[j] = class_prob + feature_probs\n",
    "\n",
    "            predictions[i] = np.argmax(posteriors)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    correct_predictions = np.sum(y_true == y_pred)\n",
    "    total_samples = len(y_true)\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    return accuracy\n",
    "\n",
    "# Instantiate GaussianNaiveBayes model\n",
    "gnb_model = GaussianNaiveBayes()\n",
    "\n",
    "# Train the model\n",
    "gnb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "gnb_predictions = gnb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_gnb = calculate_accuracy(y_test, gnb_predictions)\n",
    "\n",
    "print(f\"Gaussian Naive Bayes Accuracy: {accuracy_gnb * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorical Approach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical Naive Bayes Accuracy: 47.98%\n"
     ]
    }
   ],
   "source": [
    "class CategoricalNaiveBayes:\n",
    "    def _init_(self):\n",
    "        self.class_probs = None\n",
    "        self.feature_probs = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        unique_classes = np.unique(y)\n",
    "        num_classes = len(unique_classes)\n",
    "\n",
    "        self.class_probs = np.zeros(num_classes)\n",
    "        self.feature_probs = []\n",
    "\n",
    "        for i, c in enumerate(unique_classes):\n",
    "            class_mask = (y == c)\n",
    "            self.class_probs[i] = np.sum(class_mask) / num_samples\n",
    "\n",
    "            class_feature_probs = []\n",
    "            for j in range(num_features):\n",
    "                feature_values = np.unique(X[class_mask, j])\n",
    "                total_values = len(feature_values)\n",
    "\n",
    "                # Laplace smoothing for unseen values\n",
    "                feature_probs = (np.zeros(total_values) + 1) / (total_values + 1)\n",
    "                class_feature_probs.append((feature_values, feature_probs))\n",
    "\n",
    "            self.feature_probs.append(class_feature_probs)\n",
    "\n",
    "    def predict(self, X):\n",
    "        num_samples, num_features = X.shape\n",
    "        num_classes = len(self.class_probs)\n",
    "        predictions = np.zeros(num_samples)\n",
    "\n",
    "        epsilon = 1e-10  # Small epsilon value to avoid division by zero in logarithm\n",
    "\n",
    "        for i in range(num_samples):\n",
    "            posteriors = np.zeros(num_classes)\n",
    "\n",
    "            for j in range(num_classes):\n",
    "                class_prob = np.log(self.class_probs[j])\n",
    "                feature_probs = 0\n",
    "\n",
    "                for k in range(num_features):\n",
    "                    feature_value = X[i, k]\n",
    "                    class_feature_probs = self.feature_probs[j][k]\n",
    "\n",
    "                    if feature_value in class_feature_probs[0]:\n",
    "                        idx = np.where(class_feature_probs[0] == feature_value)[0][0]\n",
    "                        feature_probs += np.log(class_feature_probs[1][idx] + epsilon)\n",
    "\n",
    "                posteriors[j] = class_prob + feature_probs\n",
    "\n",
    "            predictions[i] = np.argmax(posteriors)\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "categorical_nb_model = CategoricalNaiveBayes()\n",
    "\n",
    "# Train the model\n",
    "categorical_nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "categorical_nb_predictions = categorical_nb_model.predict(X_test)\n",
    "\n",
    "\n",
    "accuracy_categorical_nb = accuracy(y_test, categorical_nb_predictions)\n",
    "print(f\"Categorical Naive Bayes Accuracy: {accuracy_categorical_nb * 100:.2f}%\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iterations = num_iterations\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        num_samples, num_features = X.shape\n",
    "        self.weights = np.zeros(num_features)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.num_iterations):\n",
    "            model = np.dot(X, self.weights) + self.bias\n",
    "            predictions = self.sigmoid(model)\n",
    "\n",
    "            dw = (1/num_samples) * np.dot(X.T, (predictions - y))\n",
    "            db = (1/num_samples) * np.sum(predictions - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        model = np.dot(X, self.weights) + self.bias\n",
    "        predictions = self.sigmoid(model)\n",
    "        return np.round(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate LogisticRegression model\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "# Train the model\n",
    "lr_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "lr_predictions = lr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 57.97%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_lr = accuracy(y_test, lr_predictions)\n",
    "print(f\"Logistic Regression Accuracy: {accuracy_lr * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "naive_bayes_ml.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
